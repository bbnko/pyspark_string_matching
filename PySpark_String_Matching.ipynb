{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark String Matching\n",
    "### In this exercise we have receipts from 2 different sources. The task is to find receipts that are the same and flag them to be removed in the future.\n",
    "\n",
    "### Flagging by receipt total and store is not enough, therefore item description needs to be used. Due to different OCR approaches, item descriptions of the same receipts may not be identical (example: 'banana' vs 'bananas'). This needs to be accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraires and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-21\"\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "#Initializing Spark session\n",
    "spark = SparkSession.builder.master('local[1]').appName('string_matching').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "df = spark.read.csv('dummy_receipt_file.csv', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+-------------+------+----------------+\n",
      "| source|  receipt_id|user_id|receipt_total| store|item_description|\n",
      "+-------+------------+-------+-------------+------+----------------+\n",
      "|source1|s1u110store1|   s1u1|           10|store1|           apple|\n",
      "|source1|s1u110store1|   s1u1|           10|store1|          banana|\n",
      "|source1|s1u217store2|   s1u2|           17|store2|             tea|\n",
      "|source1|s1u217store2|   s1u2|           17|store2|           sugar|\n",
      "|source1|s1u217store2|   s1u2|           17|store2|       paper bag|\n",
      "|source1|s1u325store3|   s1u3|           25|store3|        water 1L|\n",
      "|source1|s1u325store3|   s1u3|           25|store3|    orange juice|\n",
      "|source1|s1u325store3|   s1u3|           25|store3|     plastic bag|\n",
      "|source2|s2u110store1|   s2u1|           10|store1|         bananas|\n",
      "|source2|s2u110store1|   s2u1|           10|store1|          apples|\n",
      "|source2|s2u217store2|   s2u2|           17|store2|             tea|\n",
      "|source2|s2u217store2|   s2u2|           17|store2|           sugar|\n",
      "|source2|s2u217store2|   s2u2|           17|store2|       paper bag|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|       ice cream|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        potatoes|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "+-------+------------+-------+-------------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking top rows\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into 2 sources\n",
    "df_source_1 = df.filter(col('source') == 'source1')\n",
    "df_source_2 = df.filter(col('source') == 'source2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+-------------+------+----------------+\n",
      "| source|  receipt_id|user_id|receipt_total| store|item_description|\n",
      "+-------+------------+-------+-------------+------+----------------+\n",
      "|source1|s1u110store1|   s1u1|           10|store1|           apple|\n",
      "|source1|s1u110store1|   s1u1|           10|store1|          banana|\n",
      "|source1|s1u217store2|   s1u2|           17|store2|             tea|\n",
      "|source1|s1u217store2|   s1u2|           17|store2|           sugar|\n",
      "|source1|s1u217store2|   s1u2|           17|store2|       paper bag|\n",
      "|source1|s1u325store3|   s1u3|           25|store3|        water 1L|\n",
      "|source1|s1u325store3|   s1u3|           25|store3|    orange juice|\n",
      "|source1|s1u325store3|   s1u3|           25|store3|     plastic bag|\n",
      "+-------+------------+-------+-------------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_source_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+-------------+------+----------------+\n",
      "| source|  receipt_id|user_id|receipt_total| store|item_description|\n",
      "+-------+------------+-------+-------------+------+----------------+\n",
      "|source2|s2u110store1|   s2u1|           10|store1|         bananas|\n",
      "|source2|s2u110store1|   s2u1|           10|store1|          apples|\n",
      "|source2|s2u217store2|   s2u2|           17|store2|             tea|\n",
      "|source2|s2u217store2|   s2u2|           17|store2|           sugar|\n",
      "|source2|s2u217store2|   s2u2|           17|store2|       paper bag|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|       ice cream|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        potatoes|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "|source2|s2u370store4|   s2u3|           70|store4|        water 1L|\n",
      "+-------+------------+-------+-------------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_source_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupping the receipts by ID and generating a list of items\n",
    "df_source_1 = df_source_1.groupBy('receipt_id', 'user_id', 'receipt_total', 'store').agg(collect_list('item_description').alias('s1_item_desc')).withColumnRenamed('receipt_id','s1_receipt_id').withColumnRenamed('user_id','s1_user_id')\n",
    "df_source_2 = df_source_2.groupBy('receipt_id', 'user_id', 'receipt_total', 'store').agg(collect_list('item_description').alias('s2_item_desc')).withColumnRenamed('receipt_id','s2_receipt_id').withColumnRenamed('user_id','s2_user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------------+------+--------------------+\n",
      "|s1_receipt_id|s1_user_id|receipt_total| store|        s1_item_desc|\n",
      "+-------------+----------+-------------+------+--------------------+\n",
      "| s1u217store2|      s1u2|           17|store2|[tea, sugar, pape...|\n",
      "| s1u325store3|      s1u3|           25|store3|[water 1L, orange...|\n",
      "| s1u110store1|      s1u1|           10|store1|     [apple, banana]|\n",
      "+-------------+----------+-------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_source_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------------+------+--------------------+\n",
      "|s2_receipt_id|s2_user_id|receipt_total| store|        s2_item_desc|\n",
      "+-------------+----------+-------------+------+--------------------+\n",
      "| s2u370store4|      s2u3|           70|store4|[ice cream, potat...|\n",
      "| s2u217store2|      s2u2|           17|store2|[tea, sugar, pape...|\n",
      "| s2u110store1|      s2u1|           10|store1|   [bananas, apples]|\n",
      "+-------------+----------+-------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_source_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching receipts from the same stores with the same totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+-------------+----------+--------------------+-------------+----------+--------------------+\n",
      "|receipt_total| store|s1_receipt_id|s1_user_id|        s1_item_desc|s2_receipt_id|s2_user_id|        s2_item_desc|\n",
      "+-------------+------+-------------+----------+--------------------+-------------+----------+--------------------+\n",
      "|           17|store2| s1u217store2|      s1u2|[tea, sugar, pape...| s2u217store2|      s2u2|[tea, sugar, pape...|\n",
      "|           10|store1| s1u110store1|      s1u1|     [apple, banana]| s2u110store1|      s2u1|   [bananas, apples]|\n",
      "+-------------+------+-------------+----------+--------------------+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_matched_receipts = df_source_1.join(df_source_2, how='inner', on=['receipt_total', 'store'])\n",
    "df_matched_receipts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the string matching for receipts that are potentially duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuzzy match UDF\n",
    "def matchstring(s1, s2):\n",
    "    return fuzz.token_sort_ratio(s1, s2)\n",
    "MatchUDF = udf(matchstring, StringType())\n",
    "\n",
    "df_matched_receipts = df_matched_receipts.withColumn(\"similarity_score\", MatchUDF(col(\"s1_item_desc\"), col(\"s2_item_desc\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+--------------------+--------------------+----------------+\n",
      "|s1_receipt_id|s2_receipt_id|        s1_item_desc|        s2_item_desc|similarity_score|\n",
      "+-------------+-------------+--------------------+--------------------+----------------+\n",
      "| s1u217store2| s2u217store2|[tea, sugar, pape...|[tea, sugar, pape...|             100|\n",
      "| s1u110store1| s2u110store1|     [apple, banana]|   [bananas, apples]|              92|\n",
      "+-------------+-------------+--------------------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_matched_receipts.select('s1_receipt_id','s2_receipt_id', 's1_item_desc', 's2_item_desc', 'similarity_score').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+--------------------+--------------------+----------------+----------------+\n",
      "|s1_receipt_id|s2_receipt_id|        s1_item_desc|        s2_item_desc|similarity_score|if_same_receipts|\n",
      "+-------------+-------------+--------------------+--------------------+----------------+----------------+\n",
      "| s1u217store2| s2u217store2|[tea, sugar, pape...|[tea, sugar, pape...|             100|            same|\n",
      "| s1u110store1| s2u110store1|     [apple, banana]|   [bananas, apples]|              92|            same|\n",
      "+-------------+-------------+--------------------+--------------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#APPLYING FUZZY SCORE LABEL - considering score of 80 and above to me a match\n",
    "df_matched_receipts = df_matched_receipts.withColumn('if_same_receipts', when((col('similarity_score') >= 80), \"same\").otherwise(\"not_same\"))\n",
    "df_matched_receipts.select('s1_receipt_id','s2_receipt_id', 's1_item_desc', 's2_item_desc', 'similarity_score', 'if_same_receipts').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done! Receipts with similarity score of 80 and above are confirmed to be the same receipt from 2 different sources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
